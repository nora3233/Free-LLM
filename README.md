# üöÄ Free LLM API Directory

> **The comprehensive, automated list of free LLM APIs and models.**  
> *Last updated: 2026-02-15*

[![Website](https://img.shields.io/badge/Website-free--llm.com-blue?style=for-the-badge)](https://free-llm.com)
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](LICENSE)
[![Auto-Updated](https://img.shields.io/badge/Updates-Daily-orange?style=for-the-badge)](#)

## üìñ Overview

This repository contains a curated list of providers offering **free access** to Large Language Models (LLMs) via API.  
The list is **automatically synchronized** with the latest resources from the community and verified availability.

For a better viewing experience with filters and comparisons, visit our website:  
üëâ **[https://free-llm.com](https://free-llm.com)**

---

## üìö Table of Contents

- [Verified Free APIs](#verified-free-apis)
- [Full Provider List](#full-provider-list)
- [Contributing](#contributing)

---
## ‚ö° Verified Free APIs

These providers offer **truly free** access (no credit card, no trial expiration) to powerful models.

| Provider | Description | Limits | Verified |
| :--- | :--- | :--- | :---: |
| **[Cerebras](https://cloud.cerebras.ai/)** | Instant inference. | 10-30 RPM | ‚úÖ |
| **[Chutes](https://chutes.ai)** | Decentralized, crypto-based compute network. Offers free access to various op... | Distributed | ‚úÖ |
| **[Cloudflare Workers AI](https://developers.cloudflare.com/workers-ai/)** | 10,000 neurons/day (~ 100-500 requests). | - | ‚úÖ |
| **[Cohere](https://cohere.com/)** | Models share a common monthly quota. | 20 requests/minute | ‚úÖ |
| **[GitHub Models](https://github.com/marketplace/models)** | Extremely restrictive limits. Dependent on Copilot subscription tier. | Varies by Copilot Tier | ‚úÖ |
| **[Google AI Studio](https://aistudio.google.com/)** | Google's prototype platform. Data is used for training outside UK/CH/EEA/EU. | 5-30 RPM | ‚úÖ |
| **[Google Vertex AI](https://console.cloud.google.com/vertex-ai/model-garden)** | Very stringent payment verification for Google Cloud. | 30-60 RPM | ‚úÖ |
| **[Groq](https://console.groq.com/)** | LPU Inference Engine. | Varies | ‚úÖ |
| **[HuggingFace Inference Providers](https://huggingface.co/inference-api)** | Serverless Inference. Limited to models < 10GB. Some popular larger models su... | - | ‚úÖ |
| **[Mistral (Codestral)](https://codestral.mistral.ai/)** | Currently free to use Codestral model. Monthly subscription based. Phone veri... | 30 requests/minute | ‚úÖ |
| **[Mistral (La Plateforme)](https://console.mistral.ai/)** | Mistral Experiment plan. Requires opting into data training and phone verific... | 1 request/second | ‚úÖ |
| **[NVIDIA NIM](https://build.nvidia.com/explore/discover)** | NVIDIA Inference Microservices. Phone verification required. Context window l... | 40 requests/minute | ‚úÖ |
| **[OpenRouter](https://openrouter.ai/)** | A community-focused router for LLMs. Offers a specific list of truly free mod... | 20 requests/minute | ‚úÖ |
| **[OVH AI Endpoints](https://endpoints.ai.cloud.ovh.net/)** | OVHcloud's AI Endpoints in Free Beta. Access variety of open source models ho... | 12 requests/minute | ‚úÖ |
| **[SambaNova](https://cloud.sambanova.ai/)** | Experience the world's fastest inference on SambaNova's SN40L regular Reconfi... | Varies | ‚úÖ |
| **[Together.AI](https://together.ai/)** | Access specific free research models from ServiceNow and others. Currently ho... | Subject to availability | ‚úÖ |

---

## üìã Full Provider List

### [AI21 Labs](https://studio.ai21.com/)

**Description:** Creators of the Jamba model family, the world's first production-grade Mamba-based LLMs. Offers massive context windows with high throughput.  
**Limits:** Standard

<details>
<summary><strong>Available Models (2)</strong></summary>

- Jamba 1.5 Large
- Jamba 1.5 Mini

</details>

---

### [AI21 Labs](https://studio.ai21.com/)

**Description:** Creators of the Jamba model family, the world's first production-grade Mamba-based LLMs. Offers massive context windows with high throughput.  
**Limits:** Standard

<details>
<summary><strong>Available Models (2)</strong></summary>

- Jamba 1.5 Large
- Jamba 1.5 Mini

</details>

---

### [AIMLAPI](https://aimlapi.com/)

**Description:** Access 200+ AI models with one API key. High limits, low latency, and 24/7 support. Supports OpenAI, Anthropic, Mistral, and many more via a single integration.  
**Limits:** High throughput

*No specific free models listed currently.*

---

### [Alibaba Cloud Model Studio](https://bailian.console.alibabacloud.com/)

**Description:** The enterprise AI platform from Alibaba Cloud. Home of the Qwen (Tongyi Qianwen) model family, offering state-of-the-art performance in coding and mathematics.  
**Limits:** Standard

<details>
<summary><strong>Available Models (3)</strong></summary>

- Qwen-Max
- Qwen-Plus
- Qwen-Turbo

</details>

---

### [Anthropic Claude](https://claude.ai/)

**Description:** Constitutional AI with industry-leading reasoning and safety. Home of the legendary Claude 4.6 Opus, widely considered the most intelligent model available. Free tier access through claude.ai with generous daily limits.  
**Limits:** Dynamic based on demand

<details>
<summary><strong>Available Models (4)</strong></summary>

- Claude 4.6 Opus
- Claude 4.5 Sonnet
- Claude 4.5 Haiku
- Claude 4.0 Opus (Legacy)

</details>

---

### [Anyscale Endpoints](https://www.anyscale.com/endpoints)

**Description:** The creators of Ray. Anyscale Endpoints provides the best price/performance for open source LLMs. Built on the Ray serving infrastructure used by OpenAI and others.  
**Limits:** Standard

*No specific free models listed currently.*

---

### [Baidu ERNIE](https://cloud.baidu.com/product/wenxinworkshop)

**Description:** China's leading LLM, ERNIE Bot (Wenxin Yiyan). Integrated deeply with Baidu's search and knowledge graph ecosystem. Strong in knowledge retention.  
**Limits:** QPS limits apply

<details>
<summary><strong>Available Models (1)</strong></summary>

- ERNIE-Speed

</details>

---

### [Baseten](https://app.baseten.co/)

**Description:** Serverless inference for any ML model. Deploy open source models or your own custom models with ease. High performance and scalable infrastructure.  
**Limits:** Dependent on deployed instance

*No specific free models listed currently.*

---

### [BentoML](https://www.bentoml.com/)

**Description:** The unified framework for building AI applications. Package models into standard artifacts and deploy them anywhere (Docker, Kubernetes, AWS Lambda) with ease.  
**Limits:** Hardware dependent

<details>
<summary><strong>Available Models (1)</strong></summary>

- OpenLLM

</details>

---

### [BigScience Workshop](https://bigscience.huggingface.co/)

**Description:** BLOOM and T5 models available free via HuggingFace. Multilingual with 46+ languages.  
**Limits:** HF Rate Limit

<details>
<summary><strong>Available Models (1)</strong></summary>

- BLOOM 176B

</details>

---

### [BLOOM Inference](https://huggingface.co/bigscience/bloom)

**Description:** The world's largest open-multilingual language model. BLOOM (176B) is capable of generating text in 46 natural languages and 13 programming languages.  
**Limits:** Shared HF limits

<details>
<summary><strong>Available Models (2)</strong></summary>

- BLOOM-176B
- BLOOMZ (Instruct)

</details>

---

### [Cerebras](https://cloud.cerebras.ai/)

**Description:** Instant inference.  
**Limits:** 10-30 RPM

<details>
<summary><strong>Available Models (6)</strong></summary>

- gpt-oss-120b
- Qwen 3 235B A22B Instruct
- Llama 3.3 70B
- Qwen 3 32B
- Llama 3.1 8B
- Z.ai GLM-4.6

</details>

---

### [Character.AI](https://character.ai/)

**Description:** Create and chat with AI characters. Unlimited free conversations with various personas.  
**Limits:** Unlimited

<details>
<summary><strong>Available Models (1)</strong></summary>

- Character LLM

</details>

---

### [Chutes](https://chutes.ai)

**Description:** Decentralized, crypto-based compute network. Offers free access to various open models run by community hosts.  
**Limits:** Distributed

<details>
<summary><strong>Available Models (1)</strong></summary>

- Various Open Models

</details>

---

### [Cloudflare Workers AI](https://developers.cloudflare.com/workers-ai/)

**Description:** 10,000 neurons/day (~ 100-500 requests).  
**Limits:** -

<details>
<summary><strong>Available Models (50)</strong></summary>

- @cf/aisingapore/gemma-sea-lion-v4-27b-it
- @cf/ibm-granite/granite-4.0-h-micro
- @cf/openai/gpt-oss-120b
- @cf/openai/gpt-oss-20b
- @cf/qwen/qwen3-30b-a3b-fp8
- DeepSeek R1 Distill Qwen 32B
- Deepseek Coder 6.7B Base (AWQ)
- Deepseek Coder 6.7B Instruct (AWQ)
- Deepseek Math 7B Instruct
- Discolm German 7B v1 (AWQ)
- Falcom 7B Instruct
- Gemma 2B Instruct (LoRA)
- Gemma 3 12B Instruct
- Gemma 7B Instruct
- Gemma 7B Instruct (LoRA)
- Hermes 2 Pro Mistral 7B
- Llama 2 13B Chat (AWQ)
- Llama 2 7B Chat (FP16)
- Llama 2 7B Chat (INT8)
- Llama 2 7B Chat (LoRA)
- Llama 3 8B Instruct
- Llama 3 8B Instruct (AWQ)
- Llama 3.1 8B Instruct (AWQ)
- Llama 3.1 8B Instruct (FP8)
- Llama 3.2 11B Vision Instruct
- Llama 3.2 1B Instruct
- Llama 3.2 3B Instruct
- Llama 3.3 70B Instruct (FP8)
- Llama 4 Scout Instruct
- Llama Guard 3 8B
- Mistral 7B Instruct v0.1
- Mistral 7B Instruct v0.1 (AWQ)
- Mistral 7B Instruct v0.2
- Mistral 7B Instruct v0.2 (LoRA)
- Mistral Small 3.1 24B Instruct
- Neural Chat 7B v3.1 (AWQ)
- OpenChat 3.5 0106
- OpenHermes 2.5 Mistral 7B (AWQ)
- Phi-2
- Qwen 1.5 0.5B Chat
- Qwen 1.5 1.8B Chat
- Qwen 1.5 14B Chat (AWQ)
- Qwen 1.5 7B Chat (AWQ)
- Qwen 2.5 Coder 32B Instruct
- Qwen QwQ 32B
- SQLCoder 7B 2
- Starling LM 7B Beta
- TinyLlama 1.1B Chat v1.0
- Una Cybertron 7B v2 (BF16)
- Zephyr 7B Beta (AWQ)

</details>

---

### [Codeium (Windsurf)](https://codeium.com/)

**Description:** The modern coding superpower. Codeium offers free, ultra-fast code completion and chat via their editor (Windsurf) and plugins. NOT a raw API.  
**Limits:** Fair use

<details>
<summary><strong>Available Models (2)</strong></summary>

- Codeium Base
- Codeium Chat

</details>

---

### [Cody by Sourcegraph](https://sourcegraph.com/cody)

**Description:** The most powerful AI coding assistant for improved codebase understanding. Cody uses Sourcegraph's code graph to provide context-aware answers solely based on your repo.  
**Limits:** 500 auto-completions/month (deprecated, now higher)

<details>
<summary><strong>Available Models (3)</strong></summary>

- Anthropic Claude 3.5 Sonnet
- GPT-4o
- Mixtral 8x7B

</details>

---

### [Cohere](https://cohere.com/)

**Description:** Models share a common monthly quota.  
**Limits:** 20 requests/minute

<details>
<summary><strong>Available Models (12)</strong></summary>

- c4ai-aya-expanse-32b
- c4ai-aya-expanse-8b
- c4ai-aya-vision-32b
- c4ai-aya-vision-8b
- command-a-03-2025
- command-a-reasoning-08-2025
- command-a-translate-08-2025
- command-a-vision-07-2025
- command-r-08-2024
- command-r-plus-08-2024
- command-r7b-12-2024
- command-r7b-arabic-02-2025

</details>

---

### [Coqui TTS](https://github.com/coqui-ai/TTS)

**Description:** Deep learning toolkit for Text-to-Speech. Run high-quality, expressive TTS models locally or train your own voice clones.  
**Limits:** Hardware dependent

<details>
<summary><strong>Available Models (2)</strong></summary>

- XTTS v2
- VITS

</details>

---

### [Core ML](https://developer.apple.com/machine-learning/core-ml/)

**Description:** Machine learning on Apple platforms. Optimize and run models locally on iOS, macOS, watchOS, and tvOS using the power of Apple Silicon.  
**Limits:** Device dependent

<details>
<summary><strong>Available Models (2)</strong></summary>

- Stable Diffusion on Core ML
- Transformers (via swift-transformers)

</details>

---

### [DeepInfra](https://deepinfra.com/)

**Description:** Cost-effective inference platform for open-source models with $5 free credits. Features a wide range of models including Llama 4, Qwen 2.5, and specialized coding/vision models.  
**Limits:** Flexible

<details>
<summary><strong>Available Models (9)</strong></summary>

- Llama 4 405B Instruct
- Llama 4 70B Instruct
- Qwen 2.5 72B Instruct
- Mixtral 8x22B Instruct
- DeepSeek R1
- Phind CodeLlama 34B
- Gemma 3 27B
- OpenChat 3.5
- Airoboros 70B

</details>

---

### [DeepSeek](https://platform.deepseek.com/)

**Description:** The open-source giant slayer. DeepSeek-V3 and R1 deliver GPT-4 level performance at a fraction of the cost. specialized in coding and complex reasoning with massive context windows.  
**Limits:** Flexible

<details>
<summary><strong>Available Models (3)</strong></summary>

- DeepSeek-R1
- DeepSeek-V3
- DeepSeek-Coder-V2

</details>

---

### [DeepSeek V3 Base](https://openrouter.ai/)

**Description:** For technical domain tasks. Free tier available on OpenRouter with 50+ requests/day.  
**Limits:** 50+ requests/day

<details>
<summary><strong>Available Models (1)</strong></summary>

- DeepSeek V3 Base

</details>

---

### [Eden AI](https://www.edenai.co/)

**Description:** The unified API for all AI providers. Access Google, OpenAI, Microsoft, AWS, and many others through a single standard API. Simplify integration and switch providers instantly.  
**Limits:** Varies by provider

*No specific free models listed currently.*

---

### [EleutherAI](https://www.eleuther.ai/)

**Description:** A grassroots non-profit AI research lab. Creators of GPT-Neo, GPT-J, and Pythia. Their models are often hosted on Hugging Face Inference API for free testing.  
**Limits:** Shared HF limits

<details>
<summary><strong>Available Models (3)</strong></summary>

- GPT-NeoX-20B
- Pythia-12B
- GPT-J-6B

</details>

---

### [Fal.ai](https://fal.ai/)

**Description:** Lightning fast media generation. Fal.ai provides the fastest inference for Stable Diffusion, Flux, and video models. Optimized for real-time creativity.  
**Limits:** Pay per mega-token/image

*No specific free models listed currently.*

---

### [Fireworks AI](https://fireworks.ai/)

**Description:** The fastest production platform for Generative AI. Run open-source models with blazing speed and efficiency. Specialized in fire-function calling and JSON mode.  
**Limits:** 600 requests/minute (Shared)

<details>
<summary><strong>Available Models (8)</strong></summary>

- Llama 4 405B Instruct
- Llama 4 70B Instruct
- Llama 3.3 70B Instruct
- Qwen 2.5 72B Instruct
- DeepSeek V3
- Mixtral 8x22B
- FireLLaVA-13B
- Flux.1 Dev

</details>

---

### [Fireworks AI](https://fireworks.ai/)

**Description:** The fastest production platform for Generative AI. Run open-source models with blazing speed and efficiency. Specialized in fire-function calling and JSON mode.  
**Limits:** 600 requests/minute (Shared)

<details>
<summary><strong>Available Models (4)</strong></summary>

- Llama 3.1 405B Instruct
- Qwen 2.5 72B Instruct
- Mixtral 8x22B
- FireLLaVA-13B

</details>

---

### [Fireworks Compound AI](https://fireworks.ai/)

**Description:** Compound AI systems with multiple models. Free tier for orchestration and routing.  
**Limits:** Rate limit applies

<details>
<summary><strong>Available Models (1)</strong></summary>

- FireFunction V1

</details>

---

### [Forefront AI](https://www.forefront.ai/)

**Description:** Multi-model chat interface. Free daily access to premium models.  
**Limits:** Daily limits

<details>
<summary><strong>Available Models (1)</strong></summary>

- Various Models

</details>

---

### [GitHub Models](https://github.com/marketplace/models)

**Description:** Extremely restrictive limits. Dependent on Copilot subscription tier.  
**Limits:** Varies by Copilot Tier

<details>
<summary><strong>Available Models (43)</strong></summary>

- AI21 Jamba 1.5 Large
- Codestral 25.01
- Cohere Command A
- Cohere Command R 08-2024
- Cohere Command R+ 08-2024
- DeepSeek-R1
- DeepSeek-R1-0528
- DeepSeek-V3-0324
- Grok 3
- Grok 3 Mini
- Llama 4 Maverick 17B 128E Instruct FP8
- Llama 4 Scout 17B 16E Instruct
- Llama-3.2-11B-Vision-Instruct
- Llama-3.2-90B-Vision-Instruct
- Llama-3.3-70B-Instruct
- MAI-DS-R1
- Meta-Llama-3.1-405B-Instruct
- Meta-Llama-3.1-8B-Instruct
- Ministral 3B
- Mistral Medium 3 (25.05)
- Mistral Small 3.1
- OpenAI GPT-4.1
- OpenAI GPT-4.1-mini
- OpenAI GPT-4.1-nano
- OpenAI GPT-4o
- OpenAI GPT-4o mini
- OpenAI Text Embedding 3 (large)
- OpenAI Text Embedding 3 (small)
- OpenAI gpt-5
- OpenAI gpt-5-chat (preview)
- OpenAI gpt-5-mini
- OpenAI gpt-5-nano
- OpenAI o1
- OpenAI o1-mini
- OpenAI o1-preview
- OpenAI o3
- OpenAI o3-mini
- OpenAI o4-mini
- Phi-4
- Phi-4-mini-instruct
- Phi-4-mini-reasoning
- Phi-4-multimodal-instruct
- Phi-4-reasoning

</details>

---

### [Google AI Studio](https://aistudio.google.com/)

**Description:** Google's prototype platform. Data is used for training outside UK/CH/EEA/EU.  
**Limits:** 5-30 RPM

<details>
<summary><strong>Available Models (7)</strong></summary>

- Gemini 3 Flash
- Gemini 2.5 Flash
- Gemini 2.5 Flash-Lite
- Gemma 3 27B Instruct
- Gemma 3 12B Instruct
- Gemma 3 4B Instruct
- Gemma 3 1B Instruct

</details>

---

### [Google Cloud Vertex AI](https://console.cloud.google.com/vertex-ai/model-garden)

**Description:** Google Cloud's enterprise-ready generative AI platform. Model Garden provides access to 130+ foundation models including Llama 3.1 and Gemini, with enterprise-grade safety and security.  
**Limits:** 60 requests/minute (Llama 3.1 70B)

<details>
<summary><strong>Available Models (3)</strong></summary>

- Llama 3.1 405B Instruct (Maas)
- Llama 3.1 70B Instruct (Maas)
- Llama 3.2 90B Vision Instruct

</details>

---

### [Google Vertex AI](https://console.cloud.google.com/vertex-ai/model-garden)

**Description:** Very stringent payment verification for Google Cloud.  
**Limits:** 30-60 RPM

<details>
<summary><strong>Available Models (3)</strong></summary>

- Llama 3.2 90B Vision Instruct
- Llama 3.1 70B Instruct
- Llama 3.1 8B Instruct

</details>

---

### [GPT4All](https://gpt4all.io/)

**Description:** A free-to-use, locally running, privacy-aware chatbot. No GPU or internet required. Runs on popular consumer hardware using CPU quantization.  
**Limits:** Hardware dependent

<details>
<summary><strong>Available Models (3)</strong></summary>

- Snoozy
- Llama 3 8B Quant
- Nomic Embed

</details>

---

### [Grok (xAI)](https://x.ai/)

**Description:** Elon Musk's AI with real-time knowledge and witty personality. Access via X Premium.  
**Limits:** None

*No specific free models listed currently.*

---

### [Groq](https://console.groq.com/)

**Description:** LPU Inference Engine.  
**Limits:** Varies

<details>
<summary><strong>Available Models (16)</strong></summary>

- Allam 2 7B
- Llama 3.1 8B
- Llama 3.3 70B
- Llama 4 Maverick 17B 128E Instruct
- Llama 4 Scout Instruct
- Whisper Large v3
- Whisper Large v3 Turbo
- groq/compound
- groq/compound-mini
- meta-llama/llama-guard-4-12b
- moonshotai/kimi-k2-instruct
- moonshotai/kimi-k2-instruct-0905
- openai/gpt-oss-120b
- openai/gpt-oss-20b
- openai/gpt-oss-safeguard-20b
- qwen/qwen3-32b

</details>

---

### [HuggingFace Inference Providers](https://huggingface.co/inference-api)

**Description:** Serverless Inference. Limited to models < 10GB. Some popular larger models supported.  
**Limits:** -

<details>
<summary><strong>Available Models (2)</strong></summary>

- Various open models across supported providers
- Various Open Models

</details>

---

### [Hyperbolic](https://app.hyperbolic.xyz/)

**Description:** Decentralized AI inference network. Access top-tier open source models like Llama 3.1 405B and DeepSeek V3 at a fraction of the cost.  
**Limits:** Standard

<details>
<summary><strong>Available Models (24)</strong></summary>

- qwen/qwen3-next-80b-a3b-thinking
- qwen/qwen3-next-80b-a3b-instruct
- qwen/qwen3-coder-480b-a35b-instruct
- qwen/qwen3-235b-a22b-instruct-2507
- qwen/qwen3-235b-a22b
- openai/gpt-oss-20b
- openai/gpt-oss-120b-turbo
- openai/gpt-oss-120b
- deepseek-ai/deepseek-r1-0528
- Qwen2.5 VL 7B Instruct
- Qwen2.5 VL 72B Instruct
- Qwen2.5 Coder 32B Instruct
- Qwen2.5 72B Instruct
- Qwen QwQ 32B
- Pixtral 12B (2409)
- Llama 3.3 70B Instruct
- Llama 3.2 3B Instruct
- Llama 3.1 8B Instruct
- Llama 3.1 70B Instruct
- Llama 3.1 405B Base
- DeepSeek V3 0324
- Llama 3.1 405B Instruct
- DeepSeek V3
- Qwen 2.5 72B

</details>

---

### [iFlytek](https://xinghuo.xfyun.cn/)

**Description:** Spark Desk (Xinghuo) Cognitive Model. A leader in voice recognition and NLP. Spark Desk excels at education, coding, and mathematical logic.  
**Limits:** 2 QPS

<details>
<summary><strong>Available Models (1)</strong></summary>

- Spark Lite

</details>

---

### [Inference.net](https://inference.net/)

**Description:** Simple, fast, and affordable API for open source models. Focuses on providing a clean developer experience with competitive pricing.  
**Limits:** Standard

<details>
<summary><strong>Available Models (2)</strong></summary>

- Llama 3 8B
- Mistral 7B

</details>

---

### [Jan.ai](https://jan.ai/)

**Description:** Run open source AI locally on your desktop. Jan is a ChatGPT-alternative that runs 100% offline, privacy-focused, and provides an OpenAI-compatible local server.  
**Limits:** Hardware dependent

<details>
<summary><strong>Available Models (3)</strong></summary>

- Llama 3 (Local)
- Mistral (Local)
- Gemma (Local)

</details>

---

### [KoboldCpp](https://github.com/LostRuins/koboldcpp)

**Description:** A single-file GGUF inference engine for LLMs. Oriented towards storytelling and roleplay, with rich features for context management and world info.  
**Limits:** Hardware dependent

<details>
<summary><strong>Available Models (1)</strong></summary>

- Any GGUF Model

</details>

---

### [Lepton AI](https://www.lepton.ai/)

**Description:** A developer-centric platform for building AI apps. Run simple, standard APIs for open source models like Llama, Mistral, and Stable Diffusion with auto-scaling.  
**Limits:** Varies

*No specific free models listed currently.*

---

### [Llama 4 Maverick](https://openrouter.ai/)

**Description:** Mixture-of-Experts (MoE) with 400B total parameters, 17B active per forward pass. Free on OpenRouter.  
**Limits:** Standard

<details>
<summary><strong>Available Models (1)</strong></summary>

- Llama 4 Maverick

</details>

---

### [llama.cpp](https://github.com/ggerganov/llama.cpp)

**Description:** Port of Facebook's LLaMA model in C/C++. The foundational project that enables running LLMs on consumer hardware (Mac, Windows, Linux, Android) with high performance.  
**Limits:** Hardware dependent

<details>
<summary><strong>Available Models (1)</strong></summary>

- Any GGUF Model

</details>

---

### [llamafile](https://github.com/Mozilla-Ocho/llamafile)

**Description:** Distribute and run LLMs with a single file. Llamafile combines llama.cpp with Cosmopolitan Libc to create multi-platform executables that run anywhere.  
**Limits:** Hardware dependent

<details>
<summary><strong>Available Models (3)</strong></summary>

- LLaVA 1.5
- Mistral 7B
- TinyLlama

</details>

---

### [LM Studio](https://lmstudio.ai/)

**Description:** The easiest way to discover, download, and run local LLMs. Features a beautiful UI, GPU offloading, and a built-in local server that mimics OpenAI's API. Perfect for non-technical users.  
**Limits:** Hardware limited

<details>
<summary><strong>Available Models (4)</strong></summary>

- Llama 3.1 (Any Size)
- Gemma 2 (Any Size)
- Mistral (Any version)
- Phi-3 (Any version)

</details>

---

### [Mathpix](https://mathpix.com/)

**Description:** Convert images and PDFs to Markdown, LaTeX, and searchable text with high accuracy. The standard for OCR in scientific and mathematical contexts.  
**Limits:** Varies

*No specific free models listed currently.*

---

### [MediaPipe (Google)](https://developers.google.com/mediapipe)

**Description:** On-device AI for everyone. Google's framework for building multimodal applied ML pipelines (Vision, Text, Audio) that run entirely on-device (Web, Mobile, Edge).  
**Limits:** Device dependent

<details>
<summary><strong>Available Models (3)</strong></summary>

- Gemma 2B (WebGPU)
- Face Detection
- Hand Tracking

</details>

---

### [Minimax](https://api.minimax.chat/)

**Description:** A leading Chinese AGI company. Known for the abab model series (abab6, abab6.5) which offers strong reasoning and role-playing capabilities.  
**Limits:** Standard

*No specific free models listed currently.*

---

### [Mistral (Codestral)](https://codestral.mistral.ai/)

**Description:** Currently free to use Codestral model. Monthly subscription based. Phone verification required.  
**Limits:** 30 requests/minute

<details>
<summary><strong>Available Models (1)</strong></summary>

- Codestral

</details>

---

### [Mistral (La Plateforme)](https://console.mistral.ai/)

**Description:** Mistral Experiment plan. Requires opting into data training and phone verification.  
**Limits:** 1 request/second

<details>
<summary><strong>Available Models (2)</strong></summary>

- Codestral
- Open and Proprietary Mistral models

</details>

---

### [Modal](https://modal.com/)

**Description:** The high-performance cloud for developers. Run generative AI models, large-scale batch jobs, and more with instant cold starts and pay-per-second billing.  
**Limits:** Compute based

*No specific free models listed currently.*

---

### [Moonshot AI](https://platform.moonshot.cn/)

**Description:** Creators of the Kimi Chat assistant. Moonshot specializes in massive context windows (up to 200k+) and lossless long-context retrieval.  
**Limits:** Standard

*No specific free models listed currently.*

---

### [Nat.dev](https://nat.dev/)

**Description:** The ultimate LLM playground created by Nat Friedman. Compare model outputs side-by-side, test prompts against all major providers, and benchmark performance.  
**Limits:** N/A

*No specific free models listed currently.*

---

### [Nebius](https://studio.nebius.com/)

**Description:** Efficient AI inference studio. Access a wide range of open-source models with low latency and cost-effective pricing.  
**Limits:** Standard

<details>
<summary><strong>Available Models (3)</strong></summary>

- Llama 3.1 70B
- Mistral Large
- Qwen 2.5

</details>

---

### [Nicolas Guichou](https://www.youtube.com/watch?v=Mn-CmHfB5Uk&ab_channel=MightyMachines)

**Description:** OK super !  
**Limits:** Unknown

<details>
<summary><strong>Available Models (1)</strong></summary>

- LLAMA4

</details>

---

### [NLP Cloud](https://nlpcloud.com/home)

**Description:** High performance NLP API based on spaCy, HuggingFace, and custom models. Offers a wide range of models for NER, sentiment analysis, and generation.  
**Limits:** 3 requests/minute (Free Plan)

<details>
<summary><strong>Available Models (3)</strong></summary>

- Llama 3 8B
- Dolphin
- Paraphrase Multilingual

</details>

---

### [Novita AI](https://novita.ai/)

**Description:** AI infrastructure for developers. Offers various open-source models including Llama and Mistral, with a focus on stability and ease of use.  
**Limits:** Standard

<details>
<summary><strong>Available Models (3)</strong></summary>

- Llama 3.1 8B Instruct
- Llama 3.1 70B Instruct
- Mistral Nemo

</details>

---

### [Novita AI](https://novita.ai/)

**Description:** AI infrastructure for developers. Offers various open-source models including Llama and Mistral, with a focus on stability and ease of use.  
**Limits:** Standard

<details>
<summary><strong>Available Models (3)</strong></summary>

- Llama 3.1 8B Instruct
- Llama 3.1 70B Instruct
- Mistral Nemo

</details>

---

### [NVIDIA NIM](https://build.nvidia.com/explore/discover)

**Description:** NVIDIA Inference Microservices. Phone verification required. Context window limited.  
**Limits:** 40 requests/minute

<details>
<summary><strong>Available Models (1)</strong></summary>

- Various Open Models

</details>

---

### [Ollama](https://ollama.com/)

**Description:** The standard for local AI. Run Llama 3, Mistral, Gemma, and hundreds of other models directly on your Mac, Linux, or Windows machine. Complete privacy, zero cost, and offline capability.  
**Limits:** Hardware limited

<details>
<summary><strong>Available Models (5)</strong></summary>

- Llama 3.2 3B
- Gemma 2 9B
- Mistral Nemo 12B
- Phi-3.5 Mini
- DeepSeek Coder V2

</details>

---

### [OpenAI (GPT)](https://platform.openai.com/)

**Description:** The industry leader. Creator of GPT-5 and the o-series reasoning models. GPT-5.2 (Feb 2026) sets the new standard for AGI-level interactions.  
**Limits:** Limited access to GPT-4o/o4-mini

<details>
<summary><strong>Available Models (3)</strong></summary>

- OpenAI o4-mini
- GPT-4.1
- GPT-4o (Legacy)

</details>

---

### [OpenRouter](https://openrouter.ai/)

**Description:** A community-focused router for LLMs. Offers a specific list of truly free models with shared quotas.  
**Limits:** 20 requests/minute

<details>
<summary><strong>Available Models (32)</strong></summary>

- Gemma 3 12B Instruct
- Gemma 3 27B Instruct
- Gemma 3 4B Instruct
- Hermes 3 Llama 3.1 405B
- Llama 3.1 405B Instruct
- Llama 3.2 3B Instruct
- Llama 3.3 70B Instruct
- Mistral Small 3.1 24B Instruct
- Qwen 2.5 VL 7B Instruct
- allenai/molmo-2-8b:free
- arcee-ai/trinity-large-preview:free
- arcee-ai/trinity-mini:free
- cognitivecomputations/dolphin-mistral-24b-venice-edition:free
- deepseek/deepseek-r1-0528:free
- google/gemma-3n-e2b-it:free
- google/gemma-3n-e4b-it:free
- liquid/lfm-2.5-1.2b-instruct:free
- liquid/lfm-2.5-1.2b-thinking:free
- moonshotai/kimi-k2:free
- nvidia/nemotron-3-nano-30b-a3b:free
- nvidia/nemotron-nano-12b-v2-vl:free
- nvidia/nemotron-nano-9b-v2:free
- openai/gpt-oss-120b:free
- openai/gpt-oss-20b:free
- qwen/qwen3-4b:free
- qwen/qwen3-coder:free
- qwen/qwen3-next-80b-a3b-instruct:free
- tngtech/deepseek-r1t-chimera:free
- tngtech/deepseek-r1t2-chimera:free
- tngtech/tng-r1t-chimera:free
- upstage/solar-pro-3:free
- z-ai/glm-4.5-air:free

</details>

---

### [OpenRouter Horizon](https://openrouter.ai/)

**Description:** Various frontier models in testing. Free access while models are being evaluated.  
**Limits:** Fair Use

<details>
<summary><strong>Available Models (1)</strong></summary>

- Horizon Alpha

</details>

---

### [OpenRouter Optimus Alpha](https://openrouter.ai/)

**Description:** OpenRouter's own frontier model focused on general-purpose assistant capabilities. Completely free during testing.  
**Limits:** Fair Use

<details>
<summary><strong>Available Models (1)</strong></summary>

- Optimus Alpha

</details>

---

### [OpenRouter Quasar Alpha](https://openrouter.ai/)

**Description:** Specialized variant focused on reasoning and knowledge representation. Free during testing phase.  
**Limits:** Fair Use

<details>
<summary><strong>Available Models (1)</strong></summary>

- Quasar Alpha

</details>

---

### [OVH AI Endpoints](https://endpoints.ai.cloud.ovh.net/)

**Description:** OVHcloud's AI Endpoints in Free Beta. Access variety of open source models hosted in Europe.  
**Limits:** 12 requests/minute

<details>
<summary><strong>Available Models (9)</strong></summary>

- Codestral Mamba 7B v0.1
- DeepSeek R1 Distill Llama 70B
- Llama 3.1 70B Instruct
- Llama 3.1 8B Instruct
- Llama 3.3 70B Instruct
- Llava Next Mistral 7B
- Mistral 7B Instruct v0.3
- Mistral Nemo 2407
- Mixtral 8x7B Instruct

</details>

---

### [Perplexity AI](https://www.perplexity.ai/)

**Description:** The search-focused AI. Perplexity's API offers access to online-connected models like Llama 3 and their own Sonar models, optimized for low latency and search RAG.  
**Limits:** Paid API mostly

*No specific free models listed currently.*

---

### [Phind](https://www.phind.com/)

**Description:** AI search engine for developers. Combines search with code generation.  
**Limits:** Unknown

<details>
<summary><strong>Available Models (1)</strong></summary>

- Phind-70B

</details>

---

### [Poe](https://poe.com/)

**Description:** Quora's omni-chatbot. Chat with GPT-4, Claude 3, Llama 3, and thousands of user-created bots. Features a diverse ecosystem of creators and a unified subscription for all top models.  
**Limits:** Daily Compute Points

<details>
<summary><strong>Available Models (4)</strong></summary>

- Claude 3.5 Sonnet (Limited)
- GPT-4o (Limited)
- Llama 3.1 70B
- Flux Pro (Image)

</details>

---

### [Qwen (Alibaba)](https://bailian.console.alibabacloud.com/)

**Description:** The enterprise AI platform from Alibaba Cloud. Home of the Qwen (Tongyi Qianwen) model family, offering state-of-the-art performance in coding and mathematics.  
**Limits:** Standard

<details>
<summary><strong>Available Models (3)</strong></summary>

- Qwen-Max
- Qwen-Plus
- Qwen-Turbo

</details>

---

### [Ray Serve](https://docs.ray.io/en/latest/serve/index.html)

**Description:** Scalable production serving library for building online inference APIs. The industry standard for scaling LLMs and Python applications.  
**Limits:** Hardware dependent

<details>
<summary><strong>Available Models (1)</strong></summary>

- Custom Python Logic

</details>

---

### [Replicate](https://replicate.com/)

**Description:** Run open-source models with a single line of code. Thousands of models available, from LLMs to Stable Diffusion, running on scalable GPU infrastructure.  
**Limits:** Varies

*No specific free models listed currently.*

---

### [Roboflow](https://roboflow.com/)

**Description:** Everything you need to build computer vision applications. Annotate, train, and deploy models effortlessly. Hosts thousands of public datasets and models.  
**Limits:** 1000 inference calls / month

<details>
<summary><strong>Available Models (3)</strong></summary>

- YOLOv8
- YOLO-World
- CLIP

</details>

---

### [RunPod](https://www.runpod.io/)

**Description:** The GPU Cloud for AI. Rent GPUs globally from $0.2/hour or use Serverless Endpoints for instant auto-scaling inference of open source models.  
**Limits:** Pay per second

*No specific free models listed currently.*

---

### [Rwkv.run](https://rwkv.run/)

**Description:** RNN-based architecture with transformer performance. Efficient and scalable.  
**Limits:** Fair use

<details>
<summary><strong>Available Models (1)</strong></summary>

- RWKV-6

</details>

---

### [SambaNova](https://cloud.sambanova.ai/)

**Description:** Experience the world's fastest inference on SambaNova's SN40L regular Reconfigurable Dataflow Unit (RDU). Running Llama 3.1 405B at lightning speeds.  
**Limits:** Varies

<details>
<summary><strong>Available Models (3)</strong></summary>

- Llama 3.1 405B Instruct
- Llama 3.1 70B Instruct
- Llama 3.1 8B Instruct

</details>

---

### [SambaNova Cloud](https://cloud.sambanova.ai/)

**Description:** Experience the world's fastest inference on SambaNova's SN40L regular Reconfigurable Dataflow Unit (RDU). Running Llama 3.1 405B at lightning speeds.  
**Limits:** Varies

<details>
<summary><strong>Available Models (19)</strong></summary>

- tbd
- openai/gpt-oss-120b
- deepseek-ai/DeepSeek-V3.2
- deepseek-ai/DeepSeek-V3.1-Terminus
- deepseek-ai/DeepSeek-V3.1
- deepseek-ai/DeepSeek-V3-0324
- deepseek-ai/DeepSeek-R1-Distill-Llama-70B
- deepseek-ai/DeepSeek-R1-0528
- Whisper-Large-v3
- Qwen/Qwen3-32B
- Qwen/Qwen3-235B
- Llama-4-Maverick-17B-128E-Instruct
- Llama 3.3 70B
- Llama 3.3 70B
- Llama 3.1 8B
- E5-Mistral-7B-Instruct
- Llama 3.1 405B Instruct
- Llama 3.1 70B Instruct
- Llama 3.1 8B Instruct

</details>

---

### [Scaleway Generative APIs](https://console.scaleway.com/generative-api/models)

**Description:** European cloud provider offering managed generative AI APIs. Host to Mistral, Llama, and Qwen models with full GDPR compliance and data sovereignty.  
**Limits:** Standard

<details>
<summary><strong>Available Models (19)</strong></summary>

- voxtral-small-24b-2507
- qwen3-embedding-8b
- qwen3-coder-30b-a3b-instruct
- qwen3-235b-a22b-instruct-2507
- mistral-small-3.2-24b-instruct-2506
- holo2-30b-a3b
- gpt-oss-120b
- devstral-2-123b-instruct-2512
- Whisper Large v3
- Pixtral 12B (2409)
- Mistral Nemo 2407
- Llama 3.3 70B Instruct
- Llama 3.1 8B Instruct
- Gemma 3 27B Instruct
- DeepSeek R1 Distill Llama 70B
- BGE-Multilingual-Gemma2
- Mistral Large
- Llama 3.1 70B
- Llama 3.1 8B

</details>

---

### [SenseTime](https://platform.sensenova.cn/)

**Description:** SenseNova (SenseChat) large models. Known for superior vision capabilities and multimodal interactions. A pioneer in AI computer vision.  
**Limits:** Standard

*No specific free models listed currently.*

---

### [Stability AI](https://platform.stability.ai/)

**Description:** The leaders in open generative AI. Creators of Stable Diffusion, offering APIs for image generation, video, 3D, and audio with industry-standard control.  
**Limits:** 150 requests/10s

*No specific free models listed currently.*

---

### [Tabnine](https://www.tabnine.com/)

**Description:** The AI code assistant that you control. Private, secure, and personalized to your team's code. Runs isolated for maximum security.  
**Limits:** Fair use

<details>
<summary><strong>Available Models (1)</strong></summary>

- Tabnine Universal

</details>

---

### [Tencent Hunyuan](https://cloud.tencent.com/product/hunyuan)

**Description:** Tencent's foundation model. Deeply integrated with the WeChat ecosystem and Tencent Cloud. Excellent at long-form content generation and logical reasoning.  
**Limits:** Standard

<details>
<summary><strong>Available Models (1)</strong></summary>

- hunyuan-lite

</details>

---

### [Text Generation WebUI](https://github.com/oobabooga/text-generation-webui)

**Description:** The Swiss Army Knife of local LLMs. Highly customizable Gradio interface for running Large Language Models like Llama, GPT-J, OPT, and GALACTICA locally.  
**Limits:** Hardware dependent

<details>
<summary><strong>Available Models (1)</strong></summary>

- Any Local Model

</details>

---

### [Together Turbo](https://together.ai/)

**Description:** Ultra-fast inference with sub-50ms latency. Generous free tier for open models.  
**Limits:** High

<details>
<summary><strong>Available Models (1)</strong></summary>

- Llama 3 8B Turbo

</details>

---

### [Together.AI](https://together.ai/)

**Description:** Access specific free research models from ServiceNow and others. Currently hosting the Apriel Thinker series for free.  
**Limits:** Subject to availability

<details>
<summary><strong>Available Models (2)</strong></summary>

- Apriel 1.6 15B Thinker (Free)
- Apriel 1.5 15B Thinker (Free)

</details>

---

### [Triton Inference Server](https://developer.nvidia.com/triton-inference-server)

**Description:** NVIDIA's pro-grade open source inference serving software. Maximizes GPU utilization and supports all major frameworks (TensorRT, PyTorch, ONNX).  
**Limits:** Hardware dependent

<details>
<summary><strong>Available Models (1)</strong></summary>

- TensorRT-LLM

</details>

---

### [Upstage](https://console.upstage.ai/)

**Description:** Leading AI company specializing in DUS (Document Understanding) and Solar LLMs. Solar Pro delivers GPT-4 level performance with remarkable speed and efficiency.  
**Limits:** Standard

<details>
<summary><strong>Available Models (2)</strong></summary>

- Solar Pro
- Solar Mini

</details>

---

### [Venice.ai](https://venice.ai/)

**Description:** Privacy-first AI inference. Venice guarantees 100% privacy with no data logging, running open weights models on decentralized GPU nodes.  
**Limits:** Daily limits for free tier

*No specific free models listed currently.*

---

### [Vercel AI Gateway](https://vercel.com/docs/ai-gateway)

**Description:** Routes to various supported providers.  
**Limits:** -

*No specific free models listed currently.*

---

### [Vercel AI SDK](https://vercel.com/docs/ai-gateway)

**Description:** The AI SDK for the Vercel ecosystem. Unified API compatibility with OpenAI, Anthropic, Google, and more. Streamlines AI integration in Next.js apps.  
**Limits:** Depending on downstream provider

*No specific free models listed currently.*

---

### [Whisper API (HF)](https://huggingface.co/openai/whisper-large-v3)

**Description:** Hosted inference for OpenAI's Whisper model via Hugging Face. State-of-the-art automatic speech recognition (ASR) and translation.  
**Limits:** Rate limited (Wait times)

<details>
<summary><strong>Available Models (3)</strong></summary>

- whisper-large-v3
- whisper-large-v2
- distil-whisper

</details>

---

### [Yi AI](https://www.01.ai/)

**Description:** 01.AI's flagship open-source models. Yi-Large provides GPT-4 class performance with strong reasoning capabilities and a 200k context window.  
**Limits:** Standard

*No specific free models listed currently.*

---

### [You.com](https://you.com/)

**Description:** AI search with multiple model access. Free daily searches with citations.  
**Limits:** Unknown

<details>
<summary><strong>Available Models (1)</strong></summary>

- YouChat

</details>

---

### [Zhipu AI (GLM)](https://open.bigmodel.cn/)

**Description:** The team behind ChatGLM. Providing the GLM-4 series of models, which are open-weight and highly capable in bilingual (CN/EN) tasks and tool use.  
**Limits:** Limit applies to free GLM-4-Flash

<details>
<summary><strong>Available Models (1)</strong></summary>

- glm-4-flash

</details>

---

## ü§ù Contributing

This list is maintained automatically. If you know of a free provider that isn't listed, please verify it on [free-llm-api-resources](https://github.com/cheahjs/free-llm-api-resources) as we sync from there.

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---
*Generated by [Free-LLM.com](https://free-llm.com)*