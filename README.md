# üöÄ Free LLM API Directory

> **The comprehensive, automated list of free LLM APIs and models.**  
> *Last updated: 2026-02-16*

[![Website](https://img.shields.io/badge/Website-free--llm.com-blue?style=for-the-badge)](https://free-llm.com)
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](LICENSE)
[![Auto-Updated](https://img.shields.io/badge/Updates-Daily-orange?style=for-the-badge)](#)

## üìñ Overview

This repository contains a curated list of providers offering **free access** to Large Language Models (LLMs) via API.  
The list is **automatically synchronized** with the latest resources from the community and verified availability.

For a better viewing experience with filters and comparisons, visit our website:  
üëâ **[https://free-llm.com](https://free-llm.com)**

---

## üìö Table of Contents

- [Verified Free APIs](#verified-free-apis)
- [Full Provider List](#full-provider-list)
- [Contributing](#contributing)

---
## ‚ö° Verified Free APIs

These providers offer **truly free** access (no credit card, no trial expiration) to powerful models.

| Provider | Description | Limits | Verified |
| :--- | :--- | :--- | :---: |
| **[Cerebras](https://cerebras.ai/inference)** | Cerebras Systems offers the world's fastest AI inference service, powered by ... | 30 RPM | ‚úÖ |
| **[Chutes](https://chutes.ai)** | Decentralized, crypto-based compute network. Offers free access to various op... | Distributed | ‚úÖ |
| **[Cloudflare Workers AI](https://developers.cloudflare.com/workers-ai/)** | 10,000 neurons/day (~ 100-500 requests). | - | ‚úÖ |
| **[Cohere](https://cohere.com/)** | Models share a common monthly quota. | 20 requests/minute | ‚úÖ |
| **[GitHub Models](https://github.com/marketplace/models)** | Extremely restrictive limits. Dependent on Copilot subscription tier. | Varies by Copilot Tier | ‚úÖ |
| **[Google AI Studio](https://aistudio.google.com/)** | Google AI Studio is a web-based prototyping environment for developers to exp... | 2-15 RPM | ‚úÖ |
| **[Google Vertex AI](https://console.cloud.google.com/vertex-ai/model-garden)** | Very stringent payment verification for Google Cloud. | 30-60 RPM | ‚úÖ |
| **[Groq](https://console.groq.com/)** | LPU Inference Engine. | 30 RPM, 14.4k RPD | ‚úÖ |
| **[Hugging Face Inference](https://huggingface.co/inference-api/serverless)** | The Hugging Face Serverless Inference API allows you to access over 100,000 p... | 300 Requests / hour | ‚úÖ |
| **[Mistral (Codestral)](https://codestral.mistral.ai/)** | Currently free to use Codestral model. Monthly subscription based. Phone veri... | 30 requests/minute | ‚úÖ |
| **[Mistral (La Plateforme)](https://console.mistral.ai/)** | Mistral Experiment plan. Requires opting into data training and phone verific... | 1 request/second | ‚úÖ |
| **[NVIDIA NIM](https://build.nvidia.com/explore/discover)** | NVIDIA Inference Microservices. Phone verification required. Context window l... | 40 requests/minute | ‚úÖ |
| **[OpenRouter](https://openrouter.ai/)** | A community-focused router for LLMs. Offers a specific list of truly free mod... | 20 requests/minute | ‚úÖ |
| **[Together.AI](https://together.ai/)** | Access specific free research models from ServiceNow and others. Currently ho... | Subject to availability | ‚úÖ |

---

## üìã Full Provider List

### [AI21 Labs](https://docs.ai21.com/)

**Description:** Creators of the Jamba model family, the world's first production-grade Mamba-based LLMs. Offers massive context windows with high throughput.  
**Limits:** Standard

*No specific free models listed currently.*

---

### [AI21 Labs](https://studio.ai21.com/)

**Description:** Creators of the Jamba model family, the world's first production-grade Mamba-based LLMs. Offers massive context windows with high throughput.  
**Limits:** Standard

<details>
<summary><strong>Available Models (2)</strong></summary>

- Jamba 1.5 Large
- Jamba 1.5 Mini

</details>

---

### [AIMLAPI](https://aimlapi.com/)

**Description:** Access 200+ AI models with one API key. High limits, low latency, and 24/7 support. Supports OpenAI, Anthropic, Mistral, and many more via a single integration.  
**Limits:** High throughput

<details>
<summary><strong>Available Models (2)</strong></summary>

- Google: Gemma 3 4B Instruct (free)
- Google: Gemma 3 12B Instruct (free)

</details>

---

### [Alibaba Cloud Model Studio](https://bailian.console.alibabacloud.com/)

**Description:** The enterprise AI platform from Alibaba Cloud. Home of the Qwen (Tongyi Qianwen) model family, offering state-of-the-art performance in coding and mathematics.  
**Limits:** Standard

*No specific free models listed currently.*

---

### [Anthropic Claude](https://claude.ai/)

**Description:** Constitutional AI with industry-leading reasoning and safety. Home of the legendary Claude 4.6 Opus, widely considered the most intelligent model available. Free tier access through claude.ai with generous daily limits.  
**Limits:** Dynamic based on demand

*No specific free models listed currently.*

---

### [Anyscale Endpoints](https://www.anyscale.com/endpoints)

**Description:** The creators of Ray. Anyscale Endpoints provides the best price/performance for open source LLMs. Built on the Ray serving infrastructure used by OpenAI and others.  
**Limits:** Standard

*No specific free models listed currently.*

---

### [Baidu ERNIE](https://cloud.baidu.com/product/wenxinworkshop)

**Description:** China's leading LLM, ERNIE Bot (Wenxin Yiyan). Integrated deeply with Baidu's search and knowledge graph ecosystem. Strong in knowledge retention.  
**Limits:** QPS limits apply

<details>
<summary><strong>Available Models (2)</strong></summary>

- ERNIE Speed 128K (Free)
- ERNIE Lite 8K (Free)

</details>

---

### [Baseten](https://app.baseten.co/)

**Description:** Serverless inference for any ML model. Deploy open source models or your own custom models with ease. High performance and scalable infrastructure.  
**Limits:** Dependent on deployed instance

*No specific free models listed currently.*

---

### [BentoML](https://www.bentoml.com/)

**Description:** An Inference Platform built for speed and control, enabling deployment of any AI/ML model anywhere with tailored optimization, efficient scaling, and streamlined operations. It offers a complete solution to simplify inference infrastructure while giving full control over deployments.  
**Limits:** Hardware dependent

*No specific free models listed currently.*

---

### [BigScience Workshop](https://bigscience.huggingface.co/)

**Description:** BLOOM and T5 models available free via HuggingFace. Multilingual with 46+ languages.  
**Limits:** HF Rate Limit

<details>
<summary><strong>Available Models (1)</strong></summary>

- BLOOM 176B (via HF)

</details>

---

### [BLOOM Inference (BigScience)](https://huggingface.co/bigscience/bloom)

**Description:** Access the world's largest open-multilingual language model. BLOOM (176B) is capable of generating text in 46 natural languages and 13 programming languages, developed by over 1000 researchers.  
**Limits:** Shared HF limits

<details>
<summary><strong>Available Models (2)</strong></summary>

- BLOOM 176B
- BLOOMZ 176B (Instruct)

</details>

---

### [Cerebras](https://cerebras.ai/inference)

**Description:** Cerebras Systems offers the world's fastest AI inference service, powered by the Wafer-Scale Engine (WSE-3). It delivers instant speed for Llama and other open-source models, making it ideal for real-time applications and complex reasoning tasks.  
**Limits:** 30 RPM

<details>
<summary><strong>Available Models (2)</strong></summary>

- Llama 3.1 8B (Fast)
- Llama 3.1 70B (Fast)

</details>

---

### [Character.AI](https://character.ai/)

**Description:** Create and chat with AI characters. Unlimited free conversations with various personas.  
**Limits:** Unlimited

<details>
<summary><strong>Available Models (1)</strong></summary>

- Character.AI (Web Platform)

</details>

---

### [Chutes](https://chutes.ai)

**Description:** Decentralized, crypto-based compute network. Offers free access to various open models run by community hosts.  
**Limits:** Distributed

<details>
<summary><strong>Available Models (1)</strong></summary>

- Various Open Models

</details>

---

### [Cloudflare Workers AI](https://developers.cloudflare.com/workers-ai/)

**Description:** 10,000 neurons/day (~ 100-500 requests).  
**Limits:** -

<details>
<summary><strong>Available Models (50)</strong></summary>

- @cf/aisingapore/gemma-sea-lion-v4-27b-it
- @cf/ibm-granite/granite-4.0-h-micro
- @cf/openai/gpt-oss-120b
- @cf/openai/gpt-oss-20b
- @cf/qwen/qwen3-30b-a3b-fp8
- DeepSeek R1 Distill Qwen 32B
- Deepseek Coder 6.7B Base (AWQ)
- Deepseek Coder 6.7B Instruct (AWQ)
- Deepseek Math 7B Instruct
- Discolm German 7B v1 (AWQ)
- Falcom 7B Instruct
- Gemma 2B Instruct (LoRA)
- Gemma 3 12B Instruct
- Gemma 7B Instruct
- Gemma 7B Instruct (LoRA)
- Hermes 2 Pro Mistral 7B
- Llama 2 13B Chat (AWQ)
- Llama 2 7B Chat (FP16)
- Llama 2 7B Chat (INT8)
- Llama 2 7B Chat (LoRA)
- Llama 3 8B Instruct
- Llama 3 8B Instruct (AWQ)
- Llama 3.1 8B Instruct (AWQ)
- Llama 3.1 8B Instruct (FP8)
- Llama 3.2 11B Vision Instruct
- Llama 3.2 1B Instruct
- Llama 3.2 3B Instruct
- Llama 3.3 70B Instruct (FP8)
- Llama 4 Scout Instruct
- Llama Guard 3 8B
- Mistral 7B Instruct v0.1
- Mistral 7B Instruct v0.1 (AWQ)
- Mistral 7B Instruct v0.2
- Mistral 7B Instruct v0.2 (LoRA)
- Mistral Small 3.1 24B Instruct
- Neural Chat 7B v3.1 (AWQ)
- OpenChat 3.5 0106
- OpenHermes 2.5 Mistral 7B (AWQ)
- Phi-2
- Qwen 1.5 0.5B Chat
- Qwen 1.5 1.8B Chat
- Qwen 1.5 14B Chat (AWQ)
- Qwen 1.5 7B Chat (AWQ)
- Qwen 2.5 Coder 32B Instruct
- Qwen QwQ 32B
- SQLCoder 7B 2
- Starling LM 7B Beta
- TinyLlama 1.1B Chat v1.0
- Una Cybertron 7B v2 (BF16)
- Zephyr 7B Beta (AWQ)

</details>

---

### [Codeium (Windsurf)](https://codeium.com/)

**Description:** The modern coding superpower. Codeium offers free, ultra-fast code completion and chat via their editor (Windsurf) and plugins. NOT a raw API.  
**Limits:** Fair use

<details>
<summary><strong>Available Models (2)</strong></summary>

- Codeium Base (Autocomplete)
- Codeium Chat (Windsurf)

</details>

---

### [Cody by Sourcegraph](https://sourcegraph.com/cody)

**Description:** The most powerful AI coding assistant for improved codebase understanding. Cody uses Sourcegraph's code graph to provide context-aware answers solely based on your repo.  
**Limits:** 500 auto-completions/month (deprecated, now higher)

*No specific free models listed currently.*

---

### [Cohere](https://cohere.com/)

**Description:** Models share a common monthly quota.  
**Limits:** 20 requests/minute

*No specific free models listed currently.*

---

### [Coqui TTS](https://github.com/coqui-ai/TTS)

**Description:** Deep learning toolkit for Text-to-Speech. Run high-quality, expressive TTS models locally or train your own voice clones.  
**Limits:** Hardware dependent

<details>
<summary><strong>Available Models (2)</strong></summary>

- XTTS v2 (Local)
- VITS (Local)

</details>

---

### [Core ML](https://developer.apple.com/machine-learning/core-ml/)

**Description:** Machine learning on Apple platforms. Optimize and run models locally on iOS, macOS, watchOS, and tvOS using the power of Apple Silicon.  
**Limits:** Device dependent

<details>
<summary><strong>Available Models (3)</strong></summary>

- Stable Diffusion v1.5 (Core ML)
- Stable Diffusion XL (Core ML)
- Core ML Transformers

</details>

---

### [DeepInfra](https://deepinfra.com/)

**Description:** Cost-effective inference platform for open-source models with $5 free credits. Features a wide range of models including Llama 4, Qwen 2.5, and specialized coding/vision models.  
**Limits:** Flexible

<details>
<summary><strong>Available Models (9)</strong></summary>

- Llama 4 405B Instruct
- Llama 4 70B Instruct
- Qwen 2.5 72B Instruct
- Mixtral 8x22B Instruct
- DeepSeek R1
- Phind CodeLlama 34B
- Gemma 3 27B
- OpenChat 3.5
- Airoboros 70B

</details>

---

### [DeepSeek V3 Base](https://openrouter.ai/)

**Description:** For technical domain tasks. Free tier available on OpenRouter with 50+ requests/day.  
**Limits:** 50+ requests/day

<details>
<summary><strong>Available Models (1)</strong></summary>

- DeepSeek V3 Base

</details>

---

### [Eden AI](https://www.edenai.co/)

**Description:** The unified API for all AI providers. Access Google, OpenAI, Microsoft, AWS, and many others through a single standard API. Simplify integration and switch providers instantly.  
**Limits:** Varies by provider

*No specific free models listed currently.*

---

### [EleutherAI](https://www.eleuther.ai/)

**Description:** A grassroots non-profit AI research lab. Creators of GPT-Neo, GPT-J, and Pythia. Their models are often hosted on Hugging Face Inference API for free testing.  
**Limits:** Shared HF limits

<details>
<summary><strong>Available Models (2)</strong></summary>

- GPT-NeoX-20B (via HF)
- Pythia-12B (via HF)

</details>

---

### [Fal.ai](https://fal.ai/)

**Description:** Lightning fast media generation. Fal.ai provides the fastest inference for Stable Diffusion, Flux, and video models. Optimized for real-time creativity.  
**Limits:** Pay per mega-token/image

*No specific free models listed currently.*

---

### [Fireworks AI](https://fireworks.ai/)

**Description:** The fastest production platform for Generative AI. Run open-source models with blazing speed and efficiency. Specialized in fire-function calling and JSON mode.  
**Limits:** Shared

*No specific free models listed currently.*

---

### [Fireworks AI](https://fireworks.ai/)

**Description:** The fastest production platform for Generative AI. Run open-source models with blazing speed and efficiency. Specialized in fire-function calling and JSON mode.  
**Limits:** 600 requests/minute (Shared)

<details>
<summary><strong>Available Models (4)</strong></summary>

- Llama 3.1 405B Instruct
- Qwen 2.5 72B Instruct
- Mixtral 8x22B
- FireLLaVA-13B

</details>

---

### [Fireworks Compound AI](https://fireworks.ai/)

**Description:** Compound AI systems with multiple models. Free tier for orchestration and routing.  
**Limits:** Rate limit applies

*No specific free models listed currently.*

---

### [Forefront AI](https://www.forefront.ai/)

**Description:** Multi-model chat interface. Free daily access to premium models.  
**Limits:** Daily limits

<details>
<summary><strong>Available Models (1)</strong></summary>

- Various Models

</details>

---

### [GitHub Models](https://github.com/marketplace/models)

**Description:** Extremely restrictive limits. Dependent on Copilot subscription tier.  
**Limits:** Varies by Copilot Tier

<details>
<summary><strong>Available Models (6)</strong></summary>

- GPT-4o
- Llama 3.3 70B Instruct
- Phi-4
- Mistral Large (24.11)
- Cohere Command R+
- AI21 Jamba 1.5 Large

</details>

---

### [Google AI Studio](https://aistudio.google.com/)

**Description:** Google AI Studio is a web-based prototyping environment for developers to experiment with Gemini models. It offers a generous free tier that includes access to the latest Gemini 1.5 and 2.0 models, including Flash and Pro versions. It is designed for fast iteration and development, providing a seamless path from prototype to production with the Gemini API.  
**Limits:** 2-15 RPM

<details>
<summary><strong>Available Models (4)</strong></summary>

- Gemini 2.0 Flash
- Gemini 2.0 Flash-Lite
- Gemini 1.5 Flash
- Gemini 1.5 Pro

</details>

---

### [Google Cloud Vertex AI](https://console.cloud.google.com/vertex-ai/model-garden)

**Description:** Google Cloud's enterprise-ready generative AI platform. Model Garden provides access to 130+ foundation models including Llama 3.1 and Gemini, with enterprise-grade safety and security.  
**Limits:** 60 requests/minute (Llama 3.1 70B)

<details>
<summary><strong>Available Models (3)</strong></summary>

- Llama 3.1 405B Instruct (Maas)
- Llama 3.1 70B Instruct (Maas)
- Llama 3.2 90B Vision Instruct

</details>

---

### [Google Vertex AI](https://console.cloud.google.com/vertex-ai/model-garden)

**Description:** Very stringent payment verification for Google Cloud.  
**Limits:** 30-60 RPM

*No specific free models listed currently.*

---

### [GPT4All](https://gpt4all.io/)

**Description:** A free-to-use, locally running, privacy-aware chatbot. No GPU or internet required. Runs on popular consumer hardware using CPU quantization.  
**Limits:** Hardware dependent

<details>
<summary><strong>Available Models (3)</strong></summary>

- Snoozy
- Llama 3 8B Quant
- Nomic Embed

</details>

---

### [Grok (xAI)](https://x.ai/)

**Description:** xAI, founded by Elon Musk, offers the Grok series of models. Known for their real-time access to X (Twitter) data, spicy personality, and strong reasoning capabilities. The latest Grok 4 and 4.1 models offer state-of-the-art performance in reasoning, coding, and multimodal tasks.  
**Limits:** Dependent on credits

<details>
<summary><strong>Available Models (6)</strong></summary>

- Grok 4
- Grok 4.1
- Grok 4.1 Fast
- Grok 4 Fast
- Grok 2 (1212)
- Grok 2 Vision (1212)

</details>

---

### [Groq](https://console.groq.com/)

**Description:** LPU Inference Engine.  
**Limits:** 30 RPM, 14.4k RPD

<details>
<summary><strong>Available Models (16)</strong></summary>

- Allam 2 7B
- Llama 3.1 8B
- Llama 3.3 70B
- Llama 4 Maverick 17B
- Llama 4 Scout
- Whisper Large v3
- Whisper Large v3 Turbo
- Groq Compound
- Groq Compound Mini
- Llama Guard 4 12B
- Moonshot Kimi K2
- Moonshot Kimi K2 0905
- GPT-OSS 120B
- GPT-OSS 20B
- GPT-OSS Safeguard 20B
- Qwen3 32B

</details>

---

### [Hugging Face Inference](https://huggingface.co/inference-api/serverless)

**Description:** The Hugging Face Serverless Inference API allows you to access over 100,000 publicly available machine learning models. It is designed for prototyping and testing, allowing you to run inference on models without managing infrastructure. While not for heavy production, it offers a generous free tier for experimentation.  
**Limits:** 300 Requests / hour

<details>
<summary><strong>Available Models (5)</strong></summary>

- Llama 3.2 11B Vision
- Llama 3.1 8B Instruct
- Qwen 2.5 72B Instruct
- Gemma 2 9B Instruct
- Flux.1 Dev

</details>

---

### [Hyperbolic](https://app.hyperbolic.xyz/)

**Description:** Decentralized AI inference network. Access top-tier open source models like Llama 3.1 405B and DeepSeek V3 at a fraction of the cost.  
**Limits:** Standard

*No specific free models listed currently.*

---

### [iFlytek](https://xinghuo.xfyun.cn/)

**Description:** Spark Desk (Xinghuo) Cognitive Model. A leader in voice recognition and NLP. Spark Desk excels at education, coding, and mathematical logic.  
**Limits:** 2 QPS

<details>
<summary><strong>Available Models (1)</strong></summary>

- Spark Lite

</details>

---

### [Inference.net](https://inference.net/)

**Description:** Simple, fast, and affordable API for open source models. Focuses on providing a clean developer experience with competitive pricing.  
**Limits:** Standard

<details>
<summary><strong>Available Models (2)</strong></summary>

- Llama 3 8B
- Mistral 7B

</details>

---

### [Jan.ai](https://jan.ai/)

**Description:** Run open source AI locally on your desktop. Jan is a ChatGPT-alternative that runs 100% offline, privacy-focused, and provides an OpenAI-compatible local server.  
**Limits:** Hardware dependent

<details>
<summary><strong>Available Models (3)</strong></summary>

- Llama 3 (Local)
- Mistral (Local)
- Gemma 2 (Local)

</details>

---

### [KoboldCpp](https://github.com/LostRuins/koboldcpp)

**Description:** A single-file GGUF inference engine for LLMs. Oriented towards storytelling and roleplay, with rich features for context management and world info.  
**Limits:** Hardware dependent

<details>
<summary><strong>Available Models (1)</strong></summary>

- Any GGUF Model

</details>

---

### [Lepton AI](https://www.lepton.ai/)

**Description:** A developer-centric platform for building AI apps. Run simple, standard APIs for open source models like Llama, Mistral, and Stable Diffusion with auto-scaling.  
**Limits:** Varies

*No specific free models listed currently.*

---

### [Llama 4 Maverick](https://openrouter.ai/)

**Description:** Mixture-of-Experts (MoE) with 400B total parameters, 17B active per forward pass. Free on OpenRouter.  
**Limits:** Standard

<details>
<summary><strong>Available Models (1)</strong></summary>

- Llama 4 Maverick

</details>

---

### [llama.cpp](https://github.com/ggerganov/llama.cpp)

**Description:** Port of Facebook's LLaMA model in C/C++. The foundational project that enables running LLMs on consumer hardware (Mac, Windows, Linux, Android) with high performance.  
**Limits:** Hardware dependent

<details>
<summary><strong>Available Models (1)</strong></summary>

- Any GGUF Model

</details>

---

### [llamafile](https://github.com/Mozilla-Ocho/llamafile)

**Description:** Distribute and run LLMs with a single file. Llamafile combines llama.cpp with Cosmopolitan Libc to create multi-platform executables that run anywhere.  
**Limits:** Hardware dependent

<details>
<summary><strong>Available Models (3)</strong></summary>

- LLaVA 1.5
- Mistral 7B
- TinyLlama

</details>

---

### [LM Studio](https://lmstudio.ai/)

**Description:** The easiest way to discover, download, and run local LLMs. Features a beautiful UI, GPU offloading, and a built-in local server that mimics OpenAI's API. Perfect for non-technical users.  
**Limits:** Hardware limited

<details>
<summary><strong>Available Models (4)</strong></summary>

- Llama 3.1 (Any Size)
- Gemma 2 (Any Size)
- Mistral (Any version)
- Phi-3 (Any version)

</details>

---

### [Mathpix](https://mathpix.com/)

**Description:** Convert images and PDFs to Markdown, LaTeX, and searchable text with high accuracy. The standard for OCR in scientific and mathematical contexts.  
**Limits:** Paid only

*No specific free models listed currently.*

---

### [MediaPipe (Google)](https://developers.google.com/mediapipe)

**Description:** On-device AI for everyone. Google's framework for building multimodal applied ML pipelines (Vision, Text, Audio) that run entirely on-device (Web, Mobile, Edge).  
**Limits:** Device dependent

<details>
<summary><strong>Available Models (3)</strong></summary>

- Gemma 2B (WebGPU)
- Face Detection
- Hand Tracking

</details>

---

### [Minimax](https://api.minimax.chat/)

**Description:** A leading Chinese AGI company. Known for the abab model series (abab6, abab6.5) which offers strong reasoning and role-playing capabilities.  
**Limits:** Standard

*No specific free models listed currently.*

---

### [Mistral (Codestral)](https://codestral.mistral.ai/)

**Description:** Currently free to use Codestral model. Monthly subscription based. Phone verification required.  
**Limits:** 30 requests/minute

<details>
<summary><strong>Available Models (2)</strong></summary>

- Codestral 22B
- Codestral Mamba

</details>

---

### [Mistral (La Plateforme)](https://console.mistral.ai/)

**Description:** Mistral Experiment plan. Requires opting into data training and phone verification.  
**Limits:** 1 request/second

<details>
<summary><strong>Available Models (4)</strong></summary>

- Mistral 7B
- Mixtral 8x7B
- Mistral Small
- Mistral Nemo

</details>

---

### [Modal](https://modal.com/)

**Description:** The high-performance cloud for developers. Run generative AI models, large-scale batch jobs, and more with instant cold starts and pay-per-second billing.  
**Limits:** Compute based

<details>
<summary><strong>Available Models (1)</strong></summary>

- Any Open Source Model

</details>

---

### [Moonshot AI](https://platform.moonshot.cn/)

**Description:** Creators of the Kimi Chat assistant. Moonshot specializes in massive context windows (up to 200k+) and lossless long-context retrieval.  
**Limits:** Standard

*No specific free models listed currently.*

---

### [Nat.dev](https://nat.dev/)

**Description:** The ultimate LLM playground created by Nat Friedman. Compare model outputs side-by-side, test prompts against all major providers, and benchmark performance.  
**Limits:** N/A

*No specific free models listed currently.*

---

### [Nebius](https://studio.nebius.com/)

**Description:** Efficient AI inference studio. Access a wide range of open-source models with low latency and cost-effective pricing.  
**Limits:** Standard

*No specific free models listed currently.*

---

### [Nicolas Guichou](https://www.youtube.com/watch?v=Mn-CmHfB5Uk&ab_channel=MightyMachines)

**Description:** OK super !  
**Limits:** Unknown

<details>
<summary><strong>Available Models (1)</strong></summary>

- LLAMA4

</details>

---

### [NLP Cloud](https://nlpcloud.com/home)

**Description:** High performance NLP API based on spaCy, HuggingFace, and custom models. Offers a wide range of models for NER, sentiment analysis, and generation.  
**Limits:** 3 requests/minute (Free Plan)

<details>
<summary><strong>Available Models (3)</strong></summary>

- Llama 3 8B
- Dolphin
- Paraphrase Multilingual

</details>

---

### [Novita AI](https://novita.ai/)

**Description:** AI infrastructure for developers. Offers various open-source models including Llama and Mistral, with a focus on stability and ease of use.  
**Limits:** Standard

*No specific free models listed currently.*

---

### [Novita AI](https://novita.ai/)

**Description:** AI infrastructure for developers. Offers various open-source models including Llama and Mistral, with a focus on stability and ease of use.  
**Limits:** Standard

<details>
<summary><strong>Available Models (3)</strong></summary>

- Llama 3.1 8B Instruct
- Llama 3.1 70B Instruct
- Mistral Nemo

</details>

---

### [NVIDIA NIM](https://build.nvidia.com/explore/discover)

**Description:** NVIDIA Inference Microservices. Phone verification required. Context window limited.  
**Limits:** 40 requests/minute

*No specific free models listed currently.*

---

### [Ollama](https://ollama.com/)

**Description:** The standard for local AI. Run Llama 3, Mistral, Gemma, and hundreds of other models directly on your Mac, Linux, or Windows machine. Complete privacy, zero cost, and offline capability.  
**Limits:** Hardware limited

<details>
<summary><strong>Available Models (5)</strong></summary>

- Llama 3.2 3B
- Gemma 2 9B
- Mistral Nemo 12B
- Phi-3.5 Mini
- DeepSeek Coder V2

</details>

---

### [OpenAI (GPT)](https://platform.openai.com/)

**Description:** The industry leader. Creator of GPT-5 and the o-series reasoning models. GPT-5.2 (Feb 2026) sets the new standard for AGI-level interactions.  
**Limits:** Limited access to GPT-4o/o4-mini

*No specific free models listed currently.*

---

### [OpenRouter](https://openrouter.ai/)

**Description:** A community-focused router for LLMs. Offers a specific list of truly free models with shared quotas.  
**Limits:** 20 requests/minute

<details>
<summary><strong>Available Models (11)</strong></summary>

- Google: Gemini 2.0 Flash (free)
- Google: Gemini 2.0 Pro (free)
- Meta: Llama 3.3 70B Instruct (free)
- NVIDIA: Llama 3.1 Nemotron 70B (free)
- DeepSeek: R1 (free)
- DeepSeek: R1 Distill Llama 70B (free)
- Mistral: Small 3 (free)
- Qwen 2.5 7B Instruct (free)
- Qwen 2.5 VL 72B Instruct (free)
- Microsoft: Phi-3 Medium (free)
- Microsoft: Phi-3 Mini (free)

</details>

---

### [OpenRouter Horizon](https://openrouter.ai/)

**Description:** Various frontier models in testing. Free access while models are being evaluated.  
**Limits:** Fair Use

*No specific free models listed currently.*

---

### [OpenRouter Optimus Alpha](https://openrouter.ai/)

**Description:** OpenRouter's own frontier model focused on general-purpose assistant capabilities. Completely free during testing.  
**Limits:** Fair Use

<details>
<summary><strong>Available Models (1)</strong></summary>

- Optimus Alpha

</details>

---

### [OpenRouter Quasar Alpha](https://openrouter.ai/)

**Description:** Specialized variant focused on reasoning and knowledge representation. Free during testing phase.  
**Limits:** Fair Use

*No specific free models listed currently.*

---

### [OVH AI Endpoints](https://endpoints.ai.cloud.ovh.net/)

**Description:** OVHcloud's AI Endpoints in Beta. Access open source models hosted in Europe including Qwen3Guard, Audio, and Image generation models.  
**Limits:** 2 RPM (Anonymous) / 400 RPM (Auth)

<details>
<summary><strong>Available Models (7)</strong></summary>

- Qwen3Guard-Gen-0.6B (Beta)
- Qwen3Guard-Gen-8B (Beta)
- stable-diffusion-xl-base-v10
- nvr-tts-es-es
- nvr-tts-de-de
- nvr-tts-en-us
- nvr-tts-it-it

</details>

---

### [Perplexity AI](https://www.perplexity.ai/)

**Description:** The search-focused AI. Perplexity's API offers access to online-connected models like Llama 3 and their own Sonar models, optimized for low latency and search RAG.  
**Limits:** Paid API mostly

*No specific free models listed currently.*

---

### [Phind](https://www.phind.com/)

**Description:** AI search engine for developers. Combines search with code generation.  
**Limits:** Unknown

<details>
<summary><strong>Available Models (1)</strong></summary>

- Phind-70B

</details>

---

### [Poe](https://poe.com/)

**Description:** Quora's omni-chatbot. Chat with GPT-4, Claude 3, Llama 3, and thousands of user-created bots. Features a diverse ecosystem of creators and a unified subscription for all top models.  
**Limits:** Daily Compute Points

<details>
<summary><strong>Available Models (4)</strong></summary>

- Claude 3.5 Sonnet (Limited)
- GPT-4o (Limited)
- Llama 3.1 70B
- Flux Pro (Image)

</details>

---

### [Qwen (Alibaba)](https://bailian.console.alibabacloud.com/)

**Description:** The enterprise AI platform from Alibaba Cloud. Home of the Qwen (Tongyi Qianwen) model family, offering state-of-the-art performance in coding and mathematics.  
**Limits:** Standard

*No specific free models listed currently.*

---

### [Ray Serve](https://docs.ray.io/en/latest/serve/index.html)

**Description:** Scalable production serving library for building online inference APIs. The industry standard for scaling LLMs and Python applications.  
**Limits:** Hardware dependent

<details>
<summary><strong>Available Models (1)</strong></summary>

- Custom Python Logic

</details>

---

### [Replicate](https://replicate.com/)

**Description:** Run open-source models with a single line of code. Thousands of models available, from LLMs to Stable Diffusion, running on scalable GPU infrastructure.  
**Limits:** Varies

*No specific free models listed currently.*

---

### [Roboflow](https://roboflow.com/)

**Description:** Everything you need to build computer vision applications. Annotate, train, and deploy models effortlessly. Hosts thousands of public datasets and models.  
**Limits:** 1000 inference calls / month

<details>
<summary><strong>Available Models (3)</strong></summary>

- YOLOv8
- YOLO-World
- CLIP

</details>

---

### [RunPod](https://www.runpod.io/)

**Description:** The GPU Cloud for AI. Rent GPUs globally from $0.2/hour or use Serverless Endpoints for instant auto-scaling inference of open source models.  
**Limits:** Pay per second

*No specific free models listed currently.*

---

### [Rwkv.run](https://rwkv.run/)

**Description:** RNN-based architecture with transformer performance. Efficient and scalable.  
**Limits:** Fair use

<details>
<summary><strong>Available Models (1)</strong></summary>

- RWKV-6

</details>

---

### [SambaNova Cloud](https://cloud.sambanova.ai/)

**Description:** SambaNova Cloud delivers the world's fastest inference for open-source models like Llama 3.1 405B and Qwen 2.5, powered by the purpose-built SN40L Reconfigurable Dataflow Unit (RDU). It offers lightning-fast speed and a generous free credit for new users.  
**Limits:** Varies by model

*No specific free models listed currently.*

---

### [SambaNova Cloud](https://cloud.sambanova.ai/)

**Description:** Experience the world's fastest inference on SambaNova's SN40L regular Reconfigurable Dataflow Unit (RDU). Running Llama 3.1 405B at lightning speeds.  
**Limits:** Varies

<details>
<summary><strong>Available Models (19)</strong></summary>

- tbd
- openai/gpt-oss-120b
- deepseek-ai/DeepSeek-V3.2
- deepseek-ai/DeepSeek-V3.1-Terminus
- deepseek-ai/DeepSeek-V3.1
- deepseek-ai/DeepSeek-V3-0324
- deepseek-ai/DeepSeek-R1-Distill-Llama-70B
- deepseek-ai/DeepSeek-R1-0528
- Whisper-Large-v3
- Qwen/Qwen3-32B
- Qwen/Qwen3-235B
- Llama-4-Maverick-17B-128E-Instruct
- Llama 3.3 70B
- Llama 3.3 70B
- Llama 3.1 8B
- E5-Mistral-7B-Instruct
- Llama 3.1 405B Instruct
- Llama 3.1 70B Instruct
- Llama 3.1 8B Instruct

</details>

---

### [Scaleway Generative APIs](https://console.scaleway.com/generative-api/models)

**Description:** European cloud provider offering managed generative AI APIs. Host to Mistral, Llama, and Qwen models with full GDPR compliance and data sovereignty.  
**Limits:** Standard

*No specific free models listed currently.*

---

### [SenseTime](https://platform.sensenova.cn/)

**Description:** SenseNova (SenseChat) large models. Known for superior vision capabilities and multimodal interactions. A pioneer in AI computer vision.  
**Limits:** Standard

*No specific free models listed currently.*

---

### [Stability AI](https://platform.stability.ai/)

**Description:** The leaders in open generative AI. Creators of Stable Diffusion, offering APIs for image generation, video, 3D, and audio with industry-standard control.  
**Limits:** 150 requests/10s

*No specific free models listed currently.*

---

### [Tabnine](https://www.tabnine.com/)

**Description:** The AI code assistant that you control. Private, secure, and personalized to your team's code. Runs isolated for maximum security.  
**Limits:** Fair use

<details>
<summary><strong>Available Models (1)</strong></summary>

- Tabnine Universal

</details>

---

### [Tencent Hunyuan](https://cloud.tencent.com/product/hunyuan)

**Description:** Tencent's foundation model. Deeply integrated with the WeChat ecosystem and Tencent Cloud. Excellent at long-form content generation and logical reasoning.  
**Limits:** Standard

<details>
<summary><strong>Available Models (1)</strong></summary>

- hunyuan-lite

</details>

---

### [Text Generation WebUI](https://github.com/oobabooga/text-generation-webui)

**Description:** The Swiss Army Knife of local LLMs. Highly customizable Gradio interface for running Large Language Models like Llama, GPT-J, OPT, and GALACTICA locally.  
**Limits:** Hardware dependent

<details>
<summary><strong>Available Models (1)</strong></summary>

- Any Local Model

</details>

---

### [Together Turbo](https://together.ai/)

**Description:** Ultra-fast inference with sub-50ms latency. Generous free tier for open models.  
**Limits:** High

*No specific free models listed currently.*

---

### [Together.AI](https://together.ai/)

**Description:** Access specific free research models from ServiceNow and others. Currently hosting the Apriel Thinker series for free.  
**Limits:** Subject to availability

<details>
<summary><strong>Available Models (2)</strong></summary>

- Apriel 1.6 15B Thinker (Free)
- Apriel 1.5 15B Thinker (Free)

</details>

---

### [Triton Inference Server](https://developer.nvidia.com/triton-inference-server)

**Description:** NVIDIA's pro-grade open source inference serving software. Maximizes GPU utilization and supports all major frameworks (TensorRT, PyTorch, ONNX).  
**Limits:** Hardware dependent

<details>
<summary><strong>Available Models (1)</strong></summary>

- TensorRT-LLM

</details>

---

### [Upstage](https://console.upstage.ai/)

**Description:** Leading AI company specializing in DUS (Document Understanding) and Solar LLMs. Solar Pro delivers GPT-4 level performance with remarkable speed and efficiency.  
**Limits:** Standard

*No specific free models listed currently.*

---

### [Venice.ai](https://venice.ai/)

**Description:** Privacy-first AI inference. Venice guarantees 100% privacy with no data logging, running open weights models on decentralized GPU nodes.  
**Limits:** Daily limits for free tier

<details>
<summary><strong>Available Models (3)</strong></summary>

- Llama 3.1 405B
- Dolphin Mixtral
- Stable Diffusion 3

</details>

---

### [Vercel AI Gateway](https://vercel.com/docs/ai-gateway)

**Description:** Routes to various supported providers.  
**Limits:** -

*No specific free models listed currently.*

---

### [Vercel AI SDK](https://vercel.com/docs/ai-gateway)

**Description:** The AI SDK for the Vercel ecosystem. Unified API compatibility with OpenAI, Anthropic, Google, and more. Streamlines AI integration in Next.js apps.  
**Limits:** Depending on downstream provider

<details>
<summary><strong>Available Models (1)</strong></summary>

- Unified Model Access

</details>

---

### [Whisper API (HF)](https://huggingface.co/openai/whisper-large-v3)

**Description:** Hosted inference for OpenAI's Whisper model via Hugging Face. State-of-the-art automatic speech recognition (ASR) and translation.  
**Limits:** Rate limited (Wait times)

<details>
<summary><strong>Available Models (3)</strong></summary>

- whisper-large-v3
- whisper-large-v2
- distil-whisper

</details>

---

### [Yi AI](https://www.01.ai/)

**Description:** 01.AI's flagship open-source models. Yi-Large provides GPT-4 class performance with strong reasoning capabilities and a 200k context window.  
**Limits:** Standard

*No specific free models listed currently.*

---

### [You.com](https://you.com/)

**Description:** AI search with multiple model access. Free daily searches with citations.  
**Limits:** Unknown

<details>
<summary><strong>Available Models (1)</strong></summary>

- YouChat

</details>

---

### [Zhipu AI (GLM)](https://open.bigmodel.cn/)

**Description:** The team behind ChatGLM. Providing the GLM-4 series of models, which are open-weight and highly capable in bilingual (CN/EN) tasks and tool use.  
**Limits:** Limit applies to free GLM-4-Flash

<details>
<summary><strong>Available Models (1)</strong></summary>

- glm-4-flash

</details>

---

## ü§ù Contributing

This list is maintained automatically. If you know of a free provider that isn't listed, please verify it on [free-llm-api-resources](https://github.com/cheahjs/free-llm-api-resources) as we sync from there.

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---
*Generated by [Free-LLM.com](https://free-llm.com)*